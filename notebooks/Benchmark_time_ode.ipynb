{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9626d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\n",
    "    'XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4dbbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/dl264294/.local/lib/python3.8/site-packages/haiku/_src/data_structures.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax_cosmo as jc\n",
    "import jaxpm\n",
    "from jax.experimental.ode import odeint\n",
    "\n",
    "from jaxpm.painting import cic_paint\n",
    "from jaxpm.pm import linear_field, lpt, make_ode_fn, make_neural_ode_fn\n",
    "import pickle\n",
    "import haiku as hk\n",
    "from jaxpm.nn import NeuralSplineFourierFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cce344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/dl264294/.local/lib/python3.8/site-packages/haiku/_src/data_structures.py:206: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, structure = jax.tree_flatten(mapping)\n"
     ]
    }
   ],
   "source": [
    "params =pickle.load(open('/local/home/dl264294/flowpm/notebooks/camels_25_64_pkloss.params', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007463de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Omega_c= 0.2589\n",
    "Omega_b=0.04860\n",
    "sigma8= 0.8159\n",
    "n_s= 0.9667\n",
    "h= 0.6774\n",
    "w0= -1.0\n",
    "mesh_shape= [128,128,128]\n",
    "box_size  = [205.,205.,205.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7b7866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/dl264294/.local/lib/python3.8/site-packages/jax_cosmo/scipy/interpolate.py:35: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  s = np.sign(np.clip(x, xp[1], xp[-2]) - xi).astype(np.int64)\n",
      "/local/home/dl264294/.local/lib/python3.8/site-packages/jax_cosmo/scipy/interpolate.py:36: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  a = (fp[ind + np.copysign(1, s).astype(np.int64)] - fp[ind]) / (\n",
      "/local/home/dl264294/.local/lib/python3.8/site-packages/jax_cosmo/scipy/interpolate.py:37: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  xp[ind + np.copysign(1, s).astype(np.int64)] - xp[ind]\n"
     ]
    }
   ],
   "source": [
    "cosmo = jc.Planck15(Omega_c=Omega_c,Omega_b=Omega_b,sigma8=sigma8,n_s=n_s,h=h,w0=w0)\n",
    "r=jnp.linspace(0., box_size[0]*11,11+1)\n",
    "r_center = 0.5 * (r[1:] + r[:-1])\n",
    "a_center = jc.background.a_of_chi(cosmo, r_center)\n",
    "stages = a_center[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c32e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0=0.14285714254594556\n",
    "k = jnp.logspace(-4, 1, 128)\n",
    "pk = jc.power.linear_matter_power(jc.Planck15(Omega_c=Omega_c,Omega_b=Omega_b,sigma8=sigma8,n_s=n_s,h=h,w0=w0), k)\n",
    "pk_fn = lambda x: jc.scipy.interpolate.interp(x.reshape([-1]), k, pk).reshape(x.shape)\n",
    "\n",
    "# Create initial conditions\n",
    "initial_conditions = linear_field(mesh_shape, box_size, pk_fn, seed=jax.random.PRNGKey(0))\n",
    "\n",
    "# Create particles\n",
    "particles = jnp.stack(jnp.meshgrid(*[jnp.arange(s) for s in mesh_shape]),axis=-1).reshape([-1,3])\n",
    "\n",
    "\n",
    "# Initial displacement\n",
    "dx, p, f = lpt(cosmo, initial_conditions, particles, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de0886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def run_simulation_ode(Omega_c, sigma8, Omega_b, n_s, h,w0):\n",
    "    res=odeint(make_ode_fn(mesh_shape), [particles+dx, p], jnp.array(stages), cosmo, rtol=1e-5, atol=1e-5)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "209c9133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 16:06:33.800978: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  add.28 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-07-02 16:06:36.721856: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3.920981573s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  add.28 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-07-02 16:06:38.821863: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  multiply.21 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-07-02 16:06:40.410266: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3.588510287s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  multiply.21 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-07-02 16:06:50.985780: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  floor.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2023-07-02 16:06:51.266544: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4.280919641s\n",
      "Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  floor.2 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit res = run_simulation_ode(Omega_c=0.2589, sigma8=0.8159, Omega_b=0.04860, n_s=0.9667, h=0.6774, w0=-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25920ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "  model = hk.without_apply_rng(hk.transform(lambda x,a : NeuralSplineFourierFilter(n_knots=16, latent_size=32)(x,a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458d6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def run_simulation_neural(Omega_c, sigma8, Omega_b, n_s, h,w0):\n",
    "    res=odeint(make_neural_ode_fn(model,mesh_shape), [particles+dx, p], jnp.array(stages), cosmo, params, rtol=1e-5, atol=1e-5)\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8e590f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/dl264294/.local/lib/python3.8/site-packages/haiku/_src/data_structures.py:214: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  self._mapping = jax.tree_unflatten(self._structure, self._leaves)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 ms ± 1.51 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tes=run_simulation_neural(Omega_c=0.2589, sigma8=0.8159, Omega_b=0.04860, n_s=0.9667, h=0.6774, w0=-1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
